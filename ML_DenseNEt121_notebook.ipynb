{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "#some code for checking gpu\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UXx-2BnVrMBo",
    "outputId": "954c5102-6b33-412f-cba9-c950668fe6cd"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install keras-tuner\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A1tEiyy6iHki",
    "outputId": "f288894f-ed3c-4d6e-e27d-b82d1cf107cd"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/128.9 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[32m112.6/128.9 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m128.9/128.9 kB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.14.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import time, warnings\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import KFold\n",
    "import keras_tuner\n",
    "from tensorflow import keras\n",
    "from keras_tuner.tuners import RandomSearch\n",
    "from keras_tuner.engine.trial import Trial\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import LeaveOneGroupOut, StratifiedKFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense,\n",
    "    Conv1D,\n",
    "    MaxPooling1D,\n",
    "    BatchNormalization,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Conv2D,\n",
    "    MaxPool2D,\n",
    "    Activation,\n",
    ")\n",
    "import tensorflow \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import keras\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D,Convolution2D,BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten,MaxPooling2D,Dropout\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "id": "SE9QHyau5ZwO",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "#class for plotting\n",
    "class PlotLearning(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.metrics = {}\n",
    "        for metric in logs:\n",
    "            self.metrics[metric] = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        # Storing metrics\n",
    "        for metric in logs:\n",
    "            if metric in self.metrics:\n",
    "                self.metrics[metric].append(logs.get(metric))\n",
    "            else:\n",
    "                self.metrics[metric] = [logs.get(metric)]\n",
    "\n",
    "        # Plotting\n",
    "        metrics = [x for x in logs if 'val' not in x]\n",
    "\n",
    "        f, axs = plt.subplots(1, len(metrics), figsize=(15, 5))\n",
    "\n",
    "        for i, metric in enumerate(metrics):\n",
    "            axs[i].plot(range(1, epoch + 2),\n",
    "                        self.metrics[metric],\n",
    "                        label=metric)\n",
    "            if logs['val_' + metric]:\n",
    "                axs[i].plot(range(1, epoch + 2),\n",
    "                            self.metrics['val_' + metric],\n",
    "                            label='val_' + metric)\n",
    "\n",
    "            axs[i].legend()\n",
    "            axs[i].grid()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def normalize(clip):\n",
    "    normalized_clip = (clip - np.min(clip)) / (np.max(clip) - np.min(clip))\n",
    "    return normalized_clip\n",
    "\n",
    "def conv_array(root_folder):\n",
    "    metadata = pd.read_csv('/content/drive/MyDrive/UrbanSound8kv2/Data_extracted/processed_data.csv')\n",
    "    folds = {}\n",
    "    for class_label in range(1, 11):\n",
    "        class_folder_path = os.path.join(root_folder, f\"fold{class_label}\")\n",
    "        image_data = []\n",
    "        all_labels = []\n",
    "        if not os.path.exists(class_folder_path):\n",
    "            continue  # Skip if the folder doesn't exist\n",
    "        for filename in tqdm.tqdm(os.listdir(class_folder_path)):\n",
    "            if filename.endswith(\".png\"):\n",
    "                image_path = os.path.join(class_folder_path, filename)\n",
    "                image = Image.open(image_path)\n",
    "                new_filename = filename.replace('.png', '.wav')\n",
    "                row_num = metadata[metadata['slice_file_name'] == new_filename].index\n",
    "                if not row_num.empty:\n",
    "                    image_array = np.array(image)\n",
    "                    if not image_array.shape == (36, 320):\n",
    "                      continue\n",
    "                    image_array = normalize(image_array)\n",
    "                    reshape_size = image_array.shape + (1,)\n",
    "                    image_array = image_array.reshape(reshape_size)\n",
    "                    label = metadata.iloc[row_num]['labelID'].values[0]\n",
    "                    all_labels.append(label)\n",
    "                    image_data.append(image_array)\n",
    "                else:\n",
    "                    print(f'{new_filename} not found')\n",
    "                    continue\n",
    "        image_data = np.array(image_data)\n",
    "        all_labels = np.array(all_labels)\n",
    "        all_labels = to_categorical(all_labels - 1, num_classes=10)\n",
    "        folds[f\"fold{class_label}\"] = [image_data, all_labels]\n",
    "    return folds\n",
    "\n",
    "\n",
    "root_folder = r\"/content/drive/MyDrive/UrbanSound8kv2/Data_extracted/melspec\"\n",
    "data = conv_array(root_folder)\n",
    "input_shape = data['fold1'][0].shape\n",
    "print(input_shape)"
   ],
   "metadata": {
    "id": "N8n3ea7bQB5v"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tensorflow.keras.backend.clear_session()\n",
    "metric = 'accuracy' #evaluation metric\n",
    "#metric = tensorflow.keras.metrics.MeanAveragePrecisionMetric(topn=2)\n",
    "loss= 'categorical_crossentropy' #loss function\n",
    "\n",
    "#training parameters\n",
    "num_epoch = 30\n",
    "batch_size =64\n",
    "early_stop = 5 # early stoppping after 3 epochs with no improvement of test data\n",
    "\n",
    "#objective to specify the objective to select the best models, and we use max_trials to specify the number of different models to try.\n",
    "objective='val_loss'\n",
    "max_trials = 8 # how many model variations to test?\n",
    "max_trial_retrys = 3 # how many trials per variation? (same model could perform differently)\n",
    "\n",
    "\n",
    "\n",
    "def model_k_cross(data):\n",
    "    list_scores = []\n",
    "    #Densenet121 model using pretrained weights from imagenet\n",
    "    model_d=DenseNet121(weights='imagenet',include_top=False, input_shape=input_shape, classes=10) \n",
    "    \n",
    "    x=model_d.output\n",
    "    x= GlobalAveragePooling2D()(x)\n",
    "    x= BatchNormalization()(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "    x= Dense(1024,activation='relu')(x) \n",
    "    x= Dense(512,activation='relu')(x) \n",
    "    x= BatchNormalization()(x)\n",
    "    x= Dropout(0.5)(x)\n",
    "    preds=Dense(8,activation='softmax')(x) #FC-layer\n",
    "    model=Model(inputs=model_d.input,outputs=preds)\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "    #To avoid the problem of overfitting, avoid training the entire network. layer.trainable=False will freeze all the layers, keeping only the last eight layers (FC) to detect edges and blobs in the image. Once the model is fitted well, it can be fine-tuned by using layer.trainable=True.\n",
    "    for layer in model.layers[:-8]:\n",
    "        layer.trainable=False\n",
    "    for layer in model.layers[-8:]:\n",
    "        layer.trainable=True\n",
    "    \n",
    "\n",
    "\n",
    "    for fold_name, fold_data in tqdm.tqdm(data.items()):\n",
    "        tensorflow.keras.backend.clear_session()\n",
    "        print(f\"Training using {fold_name} as validation\")\n",
    "        X_val, y_val = fold_data[0], fold_data[1]\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "        for other_fold_name, other_fold_data in data.items():\n",
    "            if other_fold_name == fold_name:\n",
    "                continue\n",
    "\n",
    "            X = other_fold_data[0]\n",
    "            y = other_fold_data[1]\n",
    "            X_train.extend(X)\n",
    "            y_train.extend(y)\n",
    "\n",
    "        X_train = np.array(X_train)\n",
    "        y_train = np.array(y_train)\n",
    "        \n",
    "        model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "        EarlyStoppingCallback = tensorflow.keras.callbacks.EarlyStopping(monitor='val_loss', patience=early_stop)\n",
    "\n",
    "        history = model.fit(X_train, y_train, epochs=num_epoch, batch_size=batch_size,\n",
    "                   callbacks=[EarlyStoppingCallback], validation_data=(X_val, y_val))\n",
    "\n",
    "        # Evaluation\n",
    "        scores = model.evaluate(X_val, y_val)\n",
    "        print(\"Validation accuracy:\", scores[1])\n",
    "        list_scores.append(scores[1])\n",
    "\n",
    "\n",
    "        # Plot training history - loss\n",
    "        print(history.history.keys())\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title(f\"Training Loss - {fold_name} as validation\")\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "        plt.plot(history.history['accuracy'])\n",
    "        plt.plot(history.history['val_accuracy'])\n",
    "        plt.title(f\"Accuracy - {fold_name} as validation\")\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Training accuracy', 'Validation Loss'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    average_acc = sum(list_scores) / len(list_scores)\n",
    "    print(f'List of scores{list_scores}')\n",
    "    print(f'Average accuracy: {average_acc}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#creating custom hyperparameters to inspect model performance,inspired by the network we found on kaggle\n",
    "custom_hyperparameters = {\n",
    "        'input_units': 224,\n",
    "        'n_layers': 2,\n",
    "        'conv_0_units': 64,\n",
    "        'rate': 0.2,\n",
    "        'n_connections': 1,\n",
    "        'n_nodes': 1012,\n",
    "        'conv_1_units': 128,\n",
    "    }\n",
    "\n",
    "model_k_cross(custom_hyperparameters, data)\n",
    "#model(best_hyperparameters_overall)\n"
   ],
   "metadata": {
    "id": "84CEKB6uYR3A",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "ef17dc7a-51c1-41fb-8b3a-3c8e46d592f7",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "6HHvtbA7lzOD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "77f6b8d9-be15-402f-c4d7-888c64635028"
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  }
 ]
}
